{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from ewc import EWC\n",
        "import generate_datasets as ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to evaluate the model\n",
        "def evaluate_model(model, dataloader, device='cuda'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_dataloader, test_dataloaders, criterion, optimizer, ewc=None, lambda_ewc=0.0, epochs=20, device='cuda'):\n",
        "    model.train()\n",
        "    accuracies = np.zeros((epochs, len(test_dataloaders)))\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        \n",
        "        for inputs, targets in train_dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            task_loss = criterion(outputs, targets)\n",
        "\n",
        "            # Add regularization loss if applicable\n",
        "            ewc_loss = ewc.compute_ewc_loss(model, lambda_ewc) if ewc else 0.0\n",
        "            loss = task_loss + ewc_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += task_loss.item()\n",
        "\n",
        "        # Evaluate the model after each epoch on each test set\n",
        "        for i, test_dataloader in enumerate(test_dataloaders):\n",
        "            accuracy = evaluate_model(model, test_dataloader, device)\n",
        "            accuracies[epoch, i] = accuracy\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_dataloader):.4f}, Accuracy on task {i}: {accuracy:.4f}\")\n",
        "\n",
        "    return accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load permuted datasets\n",
        "permuted_train_loaders, permuted_test_loaders, _, _ = ds.load_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Loss: 0.4210, Accuracy on task 0: 0.9431\n",
            "Epoch 2/20, Loss: 0.1395, Accuracy on task 0: 0.9554\n",
            "Epoch 3/20, Loss: 0.0932, Accuracy on task 0: 0.9584\n",
            "Epoch 4/20, Loss: 0.0679, Accuracy on task 0: 0.9616\n",
            "Epoch 5/20, Loss: 0.0508, Accuracy on task 0: 0.9617\n",
            "Epoch 6/20, Loss: 0.0394, Accuracy on task 0: 0.9666\n",
            "Epoch 7/20, Loss: 0.0306, Accuracy on task 0: 0.9673\n",
            "Epoch 8/20, Loss: 0.0243, Accuracy on task 0: 0.9689\n",
            "Epoch 9/20, Loss: 0.0193, Accuracy on task 0: 0.9683\n",
            "Epoch 10/20, Loss: 0.0159, Accuracy on task 0: 0.9702\n",
            "Epoch 11/20, Loss: 0.0130, Accuracy on task 0: 0.9697\n",
            "Epoch 12/20, Loss: 0.0110, Accuracy on task 0: 0.9712\n",
            "Epoch 13/20, Loss: 0.0092, Accuracy on task 0: 0.9719\n",
            "Epoch 14/20, Loss: 0.0079, Accuracy on task 0: 0.9723\n",
            "Epoch 15/20, Loss: 0.0069, Accuracy on task 0: 0.9719\n",
            "Epoch 16/20, Loss: 0.0061, Accuracy on task 0: 0.9717\n",
            "Epoch 17/20, Loss: 0.0054, Accuracy on task 0: 0.9738\n",
            "Epoch 18/20, Loss: 0.0048, Accuracy on task 0: 0.9719\n",
            "Epoch 19/20, Loss: 0.0044, Accuracy on task 0: 0.9734\n",
            "Epoch 20/20, Loss: 0.0040, Accuracy on task 0: 0.9728\n",
            "Epoch 1/20, Loss: 0.3957, Accuracy on task 0: 0.9440\n",
            "Epoch 1/20, Loss: 0.3957, Accuracy on task 1: 0.9427\n",
            "Epoch 2/20, Loss: 0.1366, Accuracy on task 0: 0.9390\n",
            "Epoch 2/20, Loss: 0.1366, Accuracy on task 1: 0.9567\n",
            "Epoch 3/20, Loss: 0.0895, Accuracy on task 0: 0.9369\n",
            "Epoch 3/20, Loss: 0.0895, Accuracy on task 1: 0.9557\n",
            "Epoch 4/20, Loss: 0.0645, Accuracy on task 0: 0.9355\n",
            "Epoch 4/20, Loss: 0.0645, Accuracy on task 1: 0.9623\n",
            "Epoch 5/20, Loss: 0.0480, Accuracy on task 0: 0.9347\n",
            "Epoch 5/20, Loss: 0.0480, Accuracy on task 1: 0.9656\n",
            "Epoch 6/20, Loss: 0.0365, Accuracy on task 0: 0.9348\n",
            "Epoch 6/20, Loss: 0.0365, Accuracy on task 1: 0.9677\n",
            "Epoch 7/20, Loss: 0.0282, Accuracy on task 0: 0.9268\n",
            "Epoch 7/20, Loss: 0.0282, Accuracy on task 1: 0.9696\n",
            "Epoch 8/20, Loss: 0.0220, Accuracy on task 0: 0.9280\n",
            "Epoch 8/20, Loss: 0.0220, Accuracy on task 1: 0.9696\n",
            "Epoch 9/20, Loss: 0.0178, Accuracy on task 0: 0.9276\n",
            "Epoch 9/20, Loss: 0.0178, Accuracy on task 1: 0.9707\n",
            "Epoch 10/20, Loss: 0.0143, Accuracy on task 0: 0.9242\n",
            "Epoch 10/20, Loss: 0.0143, Accuracy on task 1: 0.9698\n",
            "Epoch 11/20, Loss: 0.0118, Accuracy on task 0: 0.9284\n",
            "Epoch 11/20, Loss: 0.0118, Accuracy on task 1: 0.9712\n",
            "Epoch 12/20, Loss: 0.0098, Accuracy on task 0: 0.9237\n",
            "Epoch 12/20, Loss: 0.0098, Accuracy on task 1: 0.9718\n",
            "Epoch 13/20, Loss: 0.0085, Accuracy on task 0: 0.9267\n",
            "Epoch 13/20, Loss: 0.0085, Accuracy on task 1: 0.9709\n",
            "Epoch 14/20, Loss: 0.0074, Accuracy on task 0: 0.9244\n",
            "Epoch 14/20, Loss: 0.0074, Accuracy on task 1: 0.9718\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m ewc\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train on second task with EWC\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m accuracies_b \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ewc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermuted_train_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermuted_test_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mewc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_ewc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m ewc\u001b[38;5;241m.\u001b[39mcompute_fisher(permuted_train_loaders[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     30\u001b[0m ewc\u001b[38;5;241m.\u001b[39mupdate_params()\n",
            "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataloader, test_dataloaders, criterion, optimizer, ewc, lambda_ewc, epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m      8\u001b[0m         inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\DELL\\Documents\\EPFL\\1st Semester\\FIL\\Project\\repo\\EE411---Project\\mnist\\generate_datasets.py:51\u001b[0m, in \u001b[0;36mPermutedMNIST.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 51\u001b[0m     img, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m     img_flattened \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\u001b[38;5;241m.\u001b[39mflatten()  \n\u001b[0;32m     54\u001b[0m     permuted_image \u001b[38;5;241m=\u001b[39m img_flattened[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermutation] \n",
            "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:144\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from MNIST_functions import CustomNN, EarlyStopping, set_experiment_params\n",
        "\n",
        "# Set experiment parameters\n",
        "params = set_experiment_params('2A')\n",
        "learning_rate = params['learning_rate']\n",
        "dropout_input = params['dropout_input']\n",
        "dropout_hidden = params['dropout_hidden']\n",
        "early_stopping_enabled = params['early_stopping_enabled']\n",
        "num_hidden_layers = params['num_hidden_layers']\n",
        "width_hidden_layers = params['width_hidden_layers']\n",
        "epochs = params['epochs']\n",
        "\n",
        "# Initialize the model, criterion, optimizer, and early stopping\n",
        "model_ewc = CustomNN(num_hidden_layers=num_hidden_layers, hidden_size=width_hidden_layers, dropout_input=dropout_input, dropout_hidden=dropout_hidden).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ewc.parameters(), lr=learning_rate)\n",
        "early_stopping = EarlyStopping(patience=5) if early_stopping_enabled else None\n",
        "\n",
        "# Train on first task with EWC\n",
        "ewc = EWC(model_ewc)\n",
        "accuracies_a = train_model(model_ewc, permuted_train_loaders[0], permuted_test_loaders[0:1], criterion, optimizer, ewc=ewc, lambda_ewc=1000, epochs=epochs, device=device)\n",
        "\n",
        "ewc.compute_fisher(permuted_train_loaders[0])\n",
        "ewc.update_params()\n",
        "\n",
        "# Train on second task with EWC\n",
        "accuracies_b = train_model(model_ewc, permuted_train_loaders[1], permuted_test_loaders[0:2], criterion, optimizer, ewc=ewc, lambda_ewc=1000, epochs=epochs, device=device)\n",
        "\n",
        "ewc.compute_fisher(permuted_train_loaders[1])\n",
        "ewc.update_params()\n",
        "\n",
        "# Train on third task with EWC\n",
        "accuracies_c = train_model(model_ewc, permuted_train_loaders[2], permuted_test_loaders[0:3], criterion, optimizer, ewc=ewc, lambda_ewc=1000, epochs=epochs, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EWC - Accuracy on Task A: 0.86, Task B: 0.95, Task C: 0.97\n"
          ]
        }
      ],
      "source": [
        "# evaluate on all tasks\n",
        "acc_a_ewc = evaluate_model(model_ewc, permuted_test_loaders[0], device=device)\n",
        "acc_b_ewc = evaluate_model(model_ewc, permuted_test_loaders[1], device=device)\n",
        "acc_c_ewc = evaluate_model(model_ewc, permuted_test_loaders[2], device=device)\n",
        "\n",
        "print(f\"EWC - Accuracy on Task A: {acc_a_ewc:.2f}, Task B: {acc_b_ewc:.2f}, Task C: {acc_c_ewc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
